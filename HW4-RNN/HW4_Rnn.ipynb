{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxuVdRvdBSFi"
      },
      "source": [
        "# HW4 RNN\n",
        "Sentiment classification on Twitter comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD__8ohVBhjx"
      },
      "source": [
        "Import packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybs7iymbWbER"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FrO0GquBkN8"
      },
      "source": [
        "Download the dataset and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRjym0iYOoPN",
        "outputId": "ede51956-cf62-43b1-8fda-773afc816485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.5.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.5.4\n",
            "--2022-11-28 15:31:26--  https://docs.google.com/uc?export=download&confirm=t&id=1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.10.101, 142.251.10.139, 142.251.10.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.10.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-88-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/f44s9frm7jvuvcjkkvlsd3at61h48or7/1669649475000/03249990876179673050/*/1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy?e=download&uuid=ae93704e-4597-4eb5-92a8-c0fa54a3ca3f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-28 15:31:26--  https://doc-10-88-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/f44s9frm7jvuvcjkkvlsd3at61h48or7/1669649475000/03249990876179673050/*/1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy?e=download&uuid=ae93704e-4597-4eb5-92a8-c0fa54a3ca3f\n",
            "Resolving doc-10-88-docs.googleusercontent.com (doc-10-88-docs.googleusercontent.com)... 142.251.12.132, 2404:6800:4003:c11::84\n",
            "Connecting to doc-10-88-docs.googleusercontent.com (doc-10-88-docs.googleusercontent.com)|142.251.12.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32816331 (31M) [application/x-zip-compressed]\n",
            "Saving to: ‘DATASET.zip’\n",
            "\n",
            "DATASET.zip         100%[===================>]  31.30M   113MB/s    in 0.3s    \n",
            "\n",
            "2022-11-28 15:31:27 (113 MB/s) - ‘DATASET.zip’ saved [32816331/32816331]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gdown\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy\" -O DATASET.zip && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# !gdown --id \"1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy\" --output DATASET.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me7hH5JjO606",
        "outputId": "d80ea410-d057-4f2a-af3f-7b03faa4e663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DATASET.zip\n",
            "  inflating: HW4_dataset/test.csv    \n",
            "  inflating: HW4_dataset/train.csv   \n",
            "  inflating: HW4_dataset/train_nolabel.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip DATASET.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4eIbJC9ZOv5"
      },
      "source": [
        "check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rpByoZOBZRcC",
        "outputId": "139d2ca7-102a-4834-ec29-2bc277e1cb43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id  \\\n",
              "0       170000   \n",
              "1       170001   \n",
              "2       170002   \n",
              "3       170003   \n",
              "4       170004   \n",
              "...        ...   \n",
              "629995  799995   \n",
              "629996  799996   \n",
              "629997  799997   \n",
              "629998  799998   \n",
              "629999  799999   \n",
              "\n",
              "                                                                                                                                                  text  \n",
              "0                                                                                            I really feel like a vanilla slice but the shop sold out   \n",
              "1                                      @kelly208 I guess we should be thankful that the tweeps haven't tried to kill us with their event suggestions.   \n",
              "2       Last night was shit.&amp; now I have to cover someones shift meh  what's going on tonight people? Anything? I'm in summer mode for a week or 2  \n",
              "3                                                                                                                   Iris by Goo Goo Dolls make me cry   \n",
              "4           My ankle is trobbing. Tequilla helps a loottt haha lmao drunk as a skunk (WTF does that mean?) who cares haha I don't going back to party   \n",
              "...                                                                                                                                                ...  \n",
              "629995                                     @stoopidgerl Im sorry to hear about your loss.  Its always horrible to lose a pet and member of the family.  \n",
              "629996                                                                                                        @RhapsodyInBleh if you go on skype sure   \n",
              "629997                                                                                                                         watching daisy of love   \n",
              "629998                                                       @HoptonHouseBnB @violetbakes yes I should be, but my 7yr old son doesn't share this view   \n",
              "629999                                                   Last Night: 2 Wine Bottles, 4 Fat Blunts!. &amp; A Night To Remember With All My New Friends   \n",
              "\n",
              "[630000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d73bb9d8-59a7-46f5-a6f3-8ae8246398cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>170000</td>\n",
              "      <td>I really feel like a vanilla slice but the shop sold out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>170001</td>\n",
              "      <td>@kelly208 I guess we should be thankful that the tweeps haven't tried to kill us with their event suggestions.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>170002</td>\n",
              "      <td>Last night was shit.&amp;amp; now I have to cover someones shift meh  what's going on tonight people? Anything? I'm in summer mode for a week or 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170003</td>\n",
              "      <td>Iris by Goo Goo Dolls make me cry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>170004</td>\n",
              "      <td>My ankle is trobbing. Tequilla helps a loottt haha lmao drunk as a skunk (WTF does that mean?) who cares haha I don't going back to party</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629995</th>\n",
              "      <td>799995</td>\n",
              "      <td>@stoopidgerl Im sorry to hear about your loss.  Its always horrible to lose a pet and member of the family.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629996</th>\n",
              "      <td>799996</td>\n",
              "      <td>@RhapsodyInBleh if you go on skype sure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629997</th>\n",
              "      <td>799997</td>\n",
              "      <td>watching daisy of love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629998</th>\n",
              "      <td>799998</td>\n",
              "      <td>@HoptonHouseBnB @violetbakes yes I should be, but my 7yr old son doesn't share this view</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629999</th>\n",
              "      <td>799999</td>\n",
              "      <td>Last Night: 2 Wine Bottles, 4 Fat Blunts!. &amp;amp; A Night To Remember With All My New Friends</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>630000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d73bb9d8-59a7-46f5-a6f3-8ae8246398cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d73bb9d8-59a7-46f5-a6f3-8ae8246398cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d73bb9d8-59a7-46f5-a6f3-8ae8246398cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 2000)\n",
        "dtr = pd.read_csv(os.path.join(os.getcwd(),\"HW4_dataset/train.csv\"))\n",
        "dnl = pd.read_csv(os.path.join(os.getcwd(),\"HW4_dataset/train_nolabel.csv\"))\n",
        "# dtr[dtr[\"label\"]==1][\"text\"]\n",
        "dnl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNA6q0rnBwHP"
      },
      "source": [
        "Basic setup of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VX5NXp4WbEi"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "EPOCH_NUM = 300\n",
        "EARLY_STOP = 50\n",
        "MAX_POSITIONS_LEN = 100\n",
        "SEED = 999\n",
        "MODEL_DIR = 'model.pth'\n",
        "lr = 1e-5\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "w2v_config = {'path': 'w2v.model', 'dim': 64}\n",
        "net_config = {'hidden_dim': 64, 'num_layers': 8, 'bidirectional': True, 'fix_embedding': False}\n",
        "header_config = {'dropout': 0.5, 'hidden_dim': 64}\n",
        "assert header_config['hidden_dim'] == net_config['hidden_dim'] or header_config['hidden_dim'] == net_config['hidden_dim'] * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxOddxufB2dr"
      },
      "source": [
        "Auxiliary functions and classes definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7PZMBJSWbEk"
      },
      "outputs": [],
      "source": [
        "def parsing_text(text_list):\n",
        "    new_list = []\n",
        "    for text in text_list:\n",
        "      if \"@\" in text:\n",
        "        text = \"[person]\"\n",
        "      elif \"http\" in text:\n",
        "        text = \"[url]\"\n",
        "      elif \"$\" in text:\n",
        "        text = \"[dollar]\"\n",
        "      new_list.append(text)\n",
        "\n",
        "    return new_list\n",
        "\n",
        "def load_train_label(path='HW4_dataset/train.csv'):\n",
        "    tra_lb_pd = pd.read_csv(path)\n",
        "    label = torch.FloatTensor(tra_lb_pd['label'].values)\n",
        "    idx = tra_lb_pd['id'].tolist()\n",
        "    text = [parsing_text(s.split(' ')) for s in tra_lb_pd['text'].tolist()]\n",
        "    return idx, text, label\n",
        "\n",
        "def load_train_nolabel(path='HW4_dataset/train_nolabel.csv'):\n",
        "    tra_nlb_pd = pd.read_csv(path)\n",
        "    text = [parsing_text(s.split(' ')) for s in tra_nlb_pd['text'].tolist()]\n",
        "    return None, text, None\n",
        "\n",
        "def load_test(path='HW4_dataset/test.csv'):\n",
        "    tst_pd = pd.read_csv(path)\n",
        "    idx = tst_pd['id'].tolist()\n",
        "    text = [parsing_text(s.split(' ')) for s in tst_pd['text'].tolist()]\n",
        "    return idx, text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6JVOfd0WbEo"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self, sentences, w2v_config):\n",
        "        self.sentences = sentences\n",
        "        self.idx2word = []\n",
        "        self.word2idx = {}\n",
        "        self.embedding_matrix = []\n",
        "        self.build_word2vec(sentences, **w2v_config)\n",
        "        \n",
        "    def build_word2vec(self, x, path, dim):\n",
        "        print(path, dim)\n",
        "        if os.path.isfile(path):\n",
        "            print(\"loading word2vec model ...\")\n",
        "            w2v_model = Word2Vec.load(path)\n",
        "        else:\n",
        "            print(\"training word2vec model ...\")\n",
        "            w2v_model = Word2Vec(x, size=dim, window=5, min_count=2, workers=12, iter=5, sg=1)\n",
        "            print(\"saving word2vec model ...\")\n",
        "            w2v_model.save(path)\n",
        "            \n",
        "        self.embedding_dim = w2v_model.vector_size\n",
        "        for i, word in enumerate(w2v_model.wv.vocab):\n",
        "            self.word2idx[word] = len(self.word2idx)\n",
        "            self.idx2word.append(word)\n",
        "            self.embedding_matrix.append(w2v_model[word])\n",
        "        \n",
        "        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n",
        "        self.add_embedding('<PAD>')\n",
        "        self.add_embedding('<UNK>')\n",
        "        print(\"total words: {}\".format(len(self.embedding_matrix)))\n",
        "        \n",
        "    def add_embedding(self, word):\n",
        "        vector = torch.empty(1, self.embedding_dim)\n",
        "        torch.nn.init.uniform_(vector)\n",
        "        self.word2idx[word] = len(self.word2idx)\n",
        "        self.idx2word.append(word)\n",
        "        self.embedding_matrix = torch.cat([self.embedding_matrix, vector], 0)   \n",
        "        \n",
        "    def sentence2idx(self, sentence):\n",
        "        sentence_idx = []\n",
        "        for word in sentence:\n",
        "            if word in self.word2idx.keys():\n",
        "                sentence_idx.append(self.word2idx[word])\n",
        "            else:\n",
        "                sentence_idx.append(self.word2idx[\"<UNK>\"])\n",
        "        return torch.LongTensor(sentence_idx)\n",
        "    \n",
        "class TwitterDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, id_list, sentences, labels, preprocessor):\n",
        "        self.id_list = id_list\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.preprocessor = preprocessor\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is None: return self.id_list[idx], self.preprocessor.sentence2idx(self.sentences[idx])\n",
        "        return self.id_list[idx], self.preprocessor.sentence2idx(self.sentences[idx]), self.labels[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def collate_fn(self, data):\n",
        "        id_list = torch.LongTensor([d[0] for d in data])\n",
        "        lengths = torch.LongTensor([len(d[1]) for d in data])\n",
        "        texts = pad_sequence(\n",
        "            [d[1] for d in data], batch_first=True).contiguous()\n",
        "     \n",
        "        if self.labels == None: \n",
        "            return id_list, lengths, texts\n",
        "        else:\n",
        "          labels = torch.FloatTensor([d[2] for d in data])\n",
        "          return id_list, lengths, texts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpK_-m5pWbGZ"
      },
      "outputs": [],
      "source": [
        "train_idx, train_label_text, label = load_train_label('HW4_dataset/train.csv')\n",
        "ultrain_idx, ultrain_label_text, ullabel = load_train_nolabel('HW4_dataset/train_nolabel.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwuBppnV-ChI",
        "outputId": "bd04b3f7-c133-4749-df39-bb6360aa37e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w2v.model 64\n",
            "training word2vec model ...\n",
            "saving word2vec model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total words: 164541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        }
      ],
      "source": [
        "preprocessor = Preprocessor(train_label_text+ultrain_label_text, w2v_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAz3ZPtEqLcC",
        "outputId": "95bcd49e-8ba4-4eda-904d-e70b4876acfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "train_idx, valid_idx, train_label_text, valid_label_text, train_label, valid_label = train_test_split(train_idx, train_label_text, label, test_size=0.5)\n",
        "train_dataset, valid_dataset = TwitterDataset(train_idx, train_label_text, train_label, preprocessor), TwitterDataset(valid_idx, valid_label_text, valid_label, preprocessor)\n",
        "\n",
        "test_idx, test_text = load_test('HW4_dataset/test.csv')\n",
        "test_dataset = TwitterDataset(test_idx, test_text, None, preprocessor)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = True,\n",
        "                                            collate_fn = train_dataset.collate_fn,\n",
        "                                            num_workers = 8)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset = valid_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = False,\n",
        "                                            collate_fn = valid_dataset.collate_fn,\n",
        "                                            num_workers = 8)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = False,\n",
        "                                            collate_fn = test_dataset.collate_fn,\n",
        "                                            num_workers = 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGHVyJwjCBRB"
      },
      "source": [
        "Definition of RNN network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BtL7itbWbGk"
      },
      "outputs": [],
      "source": [
        "class Backbone(torch.nn.Module):\n",
        "    def __init__(self, embedding, hidden_dim, num_layers, bidirectional, fix_embedding=True):\n",
        "        super(Backbone, self).__init__()\n",
        "        self.embedding = embedding\n",
        "        self.encoderlayer = torch.nn.TransformerEncoderLayer(d_model=embedding.size(1), nhead=8, batch_first=True)\n",
        "        self.net = torch.nn.TransformerEncoder(self.encoderlayer, num_layers=6)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        print(\"before:\", inputs.shape)\n",
        "        inputs = self.embedding[inputs]\n",
        "        print(\"after:\", inputs.shape)\n",
        "        x = self.net(inputs)\n",
        "        return x\n",
        "    \n",
        "class Header(torch.nn.Module):\n",
        "    def __init__(self, dropout, hidden_dim):\n",
        "        super(Header, self).__init__()\n",
        "        # TODO: you should design your classifier module\n",
        "        self.classifier = torch.nn.Sequential(torch.nn.Linear(hidden_dim, int(hidden_dim/2)),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(int(hidden_dim/2), 1),\n",
        "                            torch.nn.Sigmoid())\n",
        "        \n",
        "    @ torch.no_grad()\n",
        "    def _get_length_masks(self, lengths):\n",
        "        # lengths: (batch_size, ) in cuda\n",
        "        ascending = torch.arange(MAX_POSITIONS_LEN)[:lengths.max().item()].unsqueeze(\n",
        "            0).expand(len(lengths), -1).to(lengths.device)\n",
        "        length_masks = (ascending < lengths.unsqueeze(-1)).unsqueeze(-1)\n",
        "        return length_masks\n",
        "    \n",
        "    def forward(self, inputs, lengths):\n",
        "        # the input shape should be (N, L, D∗H)\n",
        "        pad_mask = self._get_length_masks(lengths)\n",
        "        inputs = inputs * pad_mask\n",
        "        inputs = inputs.sum(dim=1)\n",
        "        out = self.classifier(inputs).squeeze()\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go3chn37CGs8"
      },
      "source": [
        "Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdfQS_0FWbG3"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, backbone, header, optimizer, criterion, device, epoch):\n",
        "\n",
        "    total_loss = []\n",
        "    total_acc = []\n",
        "    \n",
        "    for i, (idx_list, lengths, texts, labels) in enumerate(train_loader):\n",
        "        lengths, inputs, labels = lengths.to(device), texts.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        if not backbone is None:\n",
        "            inputs = backbone(inputs)\n",
        "        soft_predicted = header(inputs, lengths)\n",
        "        loss = criterion(soft_predicted, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            hard_predicted = (soft_predicted >= 0.5).int()\n",
        "            correct = sum(hard_predicted == labels).item()\n",
        "            batch_size = len(labels)\n",
        "        \n",
        "            print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f}'.format(epoch+1, np.mean(total_loss), np.mean(total_acc)), end='\\r')\n",
        "    backbone.train()\n",
        "    header.train()\n",
        "    return np.mean(total_loss), np.mean(total_acc)\n",
        "\n",
        "def valid(valid_loader, backbone, header, criterion, device, epoch):\n",
        "    backbone.eval()\n",
        "    header.eval()\n",
        "    with torch.no_grad():\n",
        "        total_loss = []\n",
        "        total_acc = []\n",
        "        \n",
        "        for i, (idx_list, lengths, texts, labels) in enumerate(valid_loader):\n",
        "            lengths, inputs, labels = lengths.to(device), texts.to(device), labels.to(device)\n",
        "\n",
        "            if not backbone is None:\n",
        "                inputs = backbone(inputs)\n",
        "            soft_predicted = header(inputs, lengths)\n",
        "            loss = criterion(soft_predicted, labels)\n",
        "            total_loss.append(loss.item())\n",
        "            \n",
        "            hard_predicted = (soft_predicted >= 0.5).int()\n",
        "            correct = sum(hard_predicted == labels).item()\n",
        "            acc = correct * 100 / len(labels)\n",
        "            total_acc.append(acc)\n",
        "            \n",
        "            print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f}'.format(epoch+1, np.mean(total_loss), np.mean(total_acc)), end='\\r')\n",
        "    backbone.train()\n",
        "    header.train()\n",
        "    return np.mean(total_loss), np.mean(total_acc)\n",
        "\n",
        "            \n",
        "def run_training(train_loader, valid_loader, backbone, header, epoch_num, lr, early_stop, device, model_dir): \n",
        "    def check_point(backbone, header, loss, acc, model_dir):\n",
        "        torch.save({'backbone': backbone, 'header': header}, model_dir)\n",
        "        print(f\"save at {epoch}: {loss}\")\n",
        "    def is_stop(loss, min_loss):\n",
        "        if loss > min_loss:\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "    \n",
        "    if backbone is None:\n",
        "        trainable_paras = header.parameters()\n",
        "    else:\n",
        "        trainable_paras = list(backbone.parameters()) + list(header.parameters())\n",
        "        \n",
        "    optimizer = torch.optim.Adam(trainable_paras, lr=lr, eps=1e-08)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
        "\n",
        "    backbone.train()\n",
        "    header.train()\n",
        "    backbone = backbone.to(device)\n",
        "    header = header.to(device)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    min_loss = 50\n",
        "    es = 0\n",
        "    for epoch in range(epoch_num):\n",
        "        train(train_loader, backbone, header, optimizer, criterion, device, epoch)\n",
        "        lr_scheduler.step()\n",
        "        loss, acc = valid(valid_loader, backbone, header, criterion, device, epoch)\n",
        "        print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f} '.format(epoch+1, loss, acc))\n",
        "        if loss < min_loss:\n",
        "            check_point(backbone, header, loss, acc, model_dir)\n",
        "            min_loss = loss\n",
        "        if is_stop(loss, min_loss):\n",
        "          es += 1\n",
        "          if es >= early_stop:\n",
        "            break\n",
        "        else:\n",
        "          es = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbhQ7pueCJEt"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Amq9XWbEWbG9"
      },
      "outputs": [],
      "source": [
        "backbone = Backbone(preprocessor.embedding_matrix.to(device), **net_config)\n",
        "header = Header(**header_config)\n",
        "\n",
        "run_training(train_loader, valid_loader, backbone, header, EPOCH_NUM, lr, EARLY_STOP, device, MODEL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fg6zCjgCK5K"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfKCUNWRWbHi"
      },
      "outputs": [],
      "source": [
        "def run_testing(test_loader, backbone, header, device, output_path):\n",
        "  with open(output_path, 'w') as f:\n",
        "    backbone.eval()\n",
        "    header.eval()\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['id', 'label'])\n",
        "    with torch.no_grad():\n",
        "      for i, (idx_list, lengths, texts) in enumerate(test_loader):\n",
        "        lengths, inputs = lengths.to(device), texts.to(device)\n",
        "        if not backbone is None:\n",
        "          print(inputs.shape, lengths.shape)\n",
        "          inputs = backbone(inputs)\n",
        "        soft_predicted = header(inputs, lengths)\n",
        "        hard_predicted = (soft_predicted >= 0.5).int()\n",
        "        for i, p in zip(idx_list, hard_predicted):\n",
        "          writer.writerow([str(i.item()), str(p.item())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_09sRVgeWbIk"
      },
      "outputs": [],
      "source": [
        "pred_file = 'pred.csv'\n",
        "run_testing(test_loader, backbone, header, device, pred_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z2pztd-H9N8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d1ef9880-6852-477c-ea8f-3adfc1b5cc4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ecbc297f-a42b-439f-9432-0d9a3495c439\", \"SampleCode-pred.csv\", 400010)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(pred_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "z45Z9aGR-hvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = \"my heart beating like a hammer\"\n",
        "s2 = \"my hammer beating like a heart\"\n",
        "s1_embed = preprocessor.sentence2idx(parsing_text(s1.split(\" \"))).unsqueeze(0)\n",
        "s2_embed = preprocessor.sentence2idx(parsing_text(s2.split(\" \"))).unsqueeze(0)"
      ],
      "metadata": {
        "id": "-44kybfu-hMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = torch.load(\"model_encoder_loss444.pth\")[\"backbone\"].to(device)\n",
        "header = torch.load(\"model_encoder_loss444.pth\")[\"header\"].to(device)"
      ],
      "metadata": {
        "id": "lC06SSATYLK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone.eval()\n",
        "header.eval()\n",
        "\n",
        "inputs = torch.cat((s1_embed, s2_embed))\n",
        "lengths = torch.LongTensor([6,6]).to(device)\n",
        "with torch.no_grad():\n",
        "  inputs = backbone(inputs)\n",
        "  soft_predicted = header(inputs, lengths)\n",
        "  hard_predicted = (soft_predicted >= 0.5).int()"
      ],
      "metadata": {
        "id": "sJ015Y0a-zwa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}